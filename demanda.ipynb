{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import statsmodels.tsa.stattools as st\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pymannkendall as mk\n",
    "from scipy.stats import kruskal\n",
    "import plotly.graph_objects as go\n",
    "from pmdarima import auto_arima\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset-case-iqvia.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['week_dt'] = pd.to_datetime(df['week_dt']).dt.date\n",
    "df['region_nm'] = df['region_nm'].astype(str)\n",
    "df['product_id'] = df['product_id'].astype(str)\n",
    "df['product_attr_1'] = df['product_attr_1'].astype(str)\n",
    "df['product_attr_2'] = df['product_attr_2'].astype(str)\n",
    "df['product_attr_3'] = df['product_attr_3'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st = df.groupby(['week_dt', 'dsupp_id', 'region_nm','product_id'])['units_qty'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st.groupby(['dsupp_id', 'region_nm','product_id']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df_st.groupby(['dsupp_id', 'region_nm','product_id']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df_count['units_qty'].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problema vendas:\n",
    "- uma unica venda ou poucas vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 5 - df_count\n",
    "df_st.query(\"dsupp_id == 1 and region_nm == 'Sul' and product_id == '185'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st.query(\"dsupp_id == 1\")[\"product_id\"].sort_values().unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não tem para todos os product_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irei preencher com valores de units_qty 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_supp_id = df['dsupp_id'].unique()\n",
    "list_regiao = df['region_nm'].unique()\n",
    "list_id = df['product_id'].unique()\n",
    "list_weeK = df['week_dt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_product([list_weeK, list_supp_id, list_id, list_regiao], \n",
    "                                    names=['week_dt', 'dsupp_id', 'product_id', 'region_nm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.DataFrame(index=index).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_full.merge(df_st, on=['week_dt', 'dsupp_id', 'product_id', 'region_nm'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['units_qty'] = df_final['units_qty'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmando se está tudo preenchido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_weeK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.groupby(['dsupp_id', 'region_nm','product_id']).count().reset_index()['units_qty'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.groupby(['dsupp_id', 'region_nm','product_id']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['week_dt'] = df_final['week_dt'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.sort_values(by='week_dt').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_supp_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sup_id in list_supp_id:\n",
    "        for regiao in list_regiao:\n",
    "            for iD in list_id:\n",
    "                a = df_final.query(f\"dsupp_id == {sup_id} and region_nm == '{regiao}' and product_id == '{iD}'\" )\n",
    "                train, test = train_test_split(a, test_size=0.2, shuffle=False)\n",
    "                print(f\"{sup_id}_{regiao}_{iD}\")\n",
    "                # Teste para saber se tendência estatisticamente significativa\n",
    "                try:\n",
    "                    mk_test = mk.original_test(train['units_qty'])                    \n",
    "                    if mk_test.p > 0.05:\n",
    "                        print(\"Tendência NÃO É estatisticamente significativa\")\n",
    "                    else:\n",
    "                        print(\"Tendência É estatisticamente significativa\")\n",
    "                except:\n",
    "                    pass\n",
    "                # Teste para saber se a série é estacionaria\n",
    "                try:\n",
    "                    adfuller_p = adfuller(train['units_qty'])\n",
    "                    if adfuller_p[1] > 0.05:\n",
    "                        print(\"Série NÃO é estacionáia\")\n",
    "                    else:\n",
    "                        print(\"Série é estacionáia\")\n",
    "                except:\n",
    "                    pass\n",
    "                # Teste para saber se a série tem sazonalidade\n",
    "                try:\n",
    "                    kw_stat, kw_p = kruskal(*train['units_qty'].to_list())\n",
    "                    if kw_p > 0.05:\n",
    "                        print(\"Sazonalidade SEM evidência estatisticas\")\n",
    "                        bool_seasonal = False\n",
    "                    else:\n",
    "                        print(\"Sazonalidade HÁ evidência estatisticas\")\n",
    "                        bool_seasonal = True\n",
    "                        acf_values = acf(train[\"units_qty\"], nlags=24)\n",
    "                        m = np.argmax(acf_values[1:]) + 1\n",
    "                except:\n",
    "                    bool_seasonal = False\n",
    "                    pass\n",
    "                print(\"****************************************************************\")\n",
    "                decomposicao = seasonal_decompose(train['units_qty'],period=7)\n",
    "                fig = go.Figure()\n",
    "                fig.add_trace(go.Scatter(x=train[\"week_dt\"], y=train[\"units_qty\"], mode=\"lines\", name=\"Série Original\", line=dict(color=\"blue\", dash=\"dot\")))\n",
    "                fig.add_trace(go.Scatter(x=train[\"week_dt\"], y=decomposicao.trend, mode=\"lines\", name=\"Tendência\", line=dict(color=\"red\", dash=\"dot\")))\n",
    "                fig.add_trace(go.Scatter(x=train[\"week_dt\"], y=decomposicao.seasonal, mode=\"lines\", name=\"Sazonalidade\", line=dict(color=\"green\", dash=\"dot\")))\n",
    "                fig.update_layout(title=\"Decomposição da Série Temporal\",\n",
    "                                    xaxis_title=\"Data\",\n",
    "                                    yaxis_title=\"Quantidade de Unidades\",\n",
    "                                    template=\"plotly_white\")\n",
    "                fig.write_html(fr\"F:\\ST\\st_{sup_id}_{regiao}_{iD}.html\")\n",
    "                if bool_seasonal:\n",
    "                    model = auto_arima(train['units_qty'],seasonal=bool_seasonal,m=m,trace=False,stepwise=True,error_action='ignore',suppress_warnings=True)\n",
    "                else: \n",
    "                    model = auto_arima(train['units_qty'], seasonal=bool_seasonal,trace=False,stepwise=True,error_action='ignore',suppress_warnings=True)\n",
    "\n",
    "                prediction = model.predict(n_periods=25)\n",
    "                mae = mean_absolute_error(test['units_qty'], prediction)\n",
    "                rmse = np.sqrt(mean_squared_error(test['units_qty'], prediction))\n",
    "                mape = np.mean(np.abs((test['units_qty'] - prediction) / test['units_qty'])) * 100\n",
    "\n",
    "                fig_erro = go.Figure(data=[go.Table(\n",
    "                    header=dict(values=[\"Métrica\", \"Valor\"],\n",
    "                                fill_color='royalblue',\n",
    "                                align='left',\n",
    "                                font=dict(color='white', size=14)),\n",
    "                    cells=dict(values=[[\"MAE\", \"RMSE\", \"MAPE\"], [f\"{mae:.4f}\", f\"{rmse:.4f}\", f\"{mape:.2f}%\"]],\n",
    "                            fill_color='lightgray',\n",
    "                            align='left',\n",
    "                            font=dict(size=14))\n",
    "                )])\n",
    "\n",
    "                fig_erro.update_layout(title=\"Métricas de Erro do Modelo ARIMA\")\n",
    "                fig_erro.write_html(fr\"F:\\ST\\st_{sup_id}_{regiao}_{iD}_erro.html\")\n",
    "\n",
    "                fig_pred = go.Figure()\n",
    "                # Série original (Treino)\n",
    "                fig_pred.add_trace(go.Scatter(x=train[\"week_dt\"], y=train[\"units_qty\"], \n",
    "                                        mode='lines', name='Treino', line=dict(color='blue')))\n",
    "                # Valores de teste\n",
    "                fig_pred.add_trace(go.Scatter(x=test[\"week_dt\"], y=test[\"units_qty\"], \n",
    "                                        mode='lines', name='Teste', line=dict(color='green')))\n",
    "                # Previsões do modelo\n",
    "                fig_pred.add_trace(go.Scatter(x=test[\"week_dt\"], y=prediction, \n",
    "                                        mode='lines', name='Previsão', \n",
    "                                        line=dict(color='red', dash='dot')))\n",
    "                fig_pred.update_layout(title=\"Previsão com ARIMA\",\n",
    "                                xaxis_title=\"Data\",\n",
    "                                yaxis_title=\"Valor\",\n",
    "                                template=\"plotly_white\")\n",
    "                fig_pred.write_html(fr\"F:\\ST\\st_{sup_id}_{regiao}_{iD}_pred.html\")\n",
    "                \n",
    "                try:\n",
    "                    del kw_stat\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    del kw_p\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    del mk_test\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    del adfuller_p\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    del a\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    del model\n",
    "                except:\n",
    "                    pass\n",
    "                gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iqvia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
